Q1 : What is the basic difference between RDBMS and Hadoop?

    RDBMS enforces strict schema on write, whereas Hadoop enforces schema on read and is more scalable as a result for many scenarios.
    
Q2 : List out the components of Hadoop?

    Hadoop encompasses HDFS and MapReduce for storage and processing.  The HDFS side of things is managed by a NameNode which orchestrate placement on DataNodes.  MapReduce is orchestrated via the JobTracker and TaskTrackers, and history is persisted on the JobHistoryServer.

Q3 : What are the processes in Hadoop FW?

    Not sure what this question is asking.  There are multiple services on the Hadoop stack that can be used for processing, such as Pig, Hive, and Mahout.
    
    There is also the underlying service architecture that executes the query / job for each of these services.

Q4 : What kind of replication is present for hdfs?

    The replication policy is managing replicas across failure domains.  The default is three replicas in three separate failure domains (racks).  Users can control the replica policy per file.
    
Q5 : Is Hadoop better for datafiles with small size?

    Not sure what the comparison is relative to, but Hadoop is inefficient at storing small files because of the amount of metadata required to store the files which adds to the memory storage pressure on the NameNode server.  

Q6: since the Hadoop command is deprecated, what can you use instead for same result

    'dfs' was deprecated; the correct command is now 'fs'